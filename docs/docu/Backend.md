# ğŸ–¥ï¸ Backend Documentation


## ğŸš€ Overview
The **backend** of the Web Scraping Project is responsible for:
- **Managing web scraping tasks** using BeautifulSoup, Scrapy, or Selenium.
- **Processing and cleaning data** before storage.
- **Providing an API** to serve the scraped data to the frontend or external applications.
- **Handling database operations** for storing and retrieving scraped data.

## ğŸ“Œ Features:
- âœ… Scrapes static websites using BeautifulSoup  
- âœ… Extracts plain text from web pages  
- âœ… Saves the scraped data as a `.txt` file  
- âœ… Returns scraped data as JSON  
- âœ… Simple & fast API 

## Prerequisites:
- Python 3.8+
- Flask
- BeautifulSoup (for HTML parsing)

## Quick Start:
To run the API locally:
```bash
python app.py
```

## Code


##     1. routes.py:
- scrape():

    ğŸ“Œ **Description:**  
This route **scrapes a static website** using **BeautifulSoup** and returns the extracted HTML.

```
@app.route("/scrape_with_bs4", methods=["POST"]) 
```
Defines a route for a specific URL and specifies which HTTP method is allowed

this Function calls the scrapes_with_bs4 function that scrapes static websites and return the data as HTML

ğŸ“Œ**Response:**

```
jsonify({"html": raw_html})
```
it returns a jsonify file and send it to the frontend to show it to the user


**Why jsonify file ?** 

It's better to return JSON to the frontend because JSON is lightweight, structured, and universally supported by typeScript

- download_txt():

ğŸ“Œ ** Description:**

   This route returns the scraped HTML content as a downloadable .txt file.

   it calls the `raw_html_to_txt_file()` to save scraped HTML into a `.txt` file
 


## 2. in scraper.py 
-`/scrape_with_bs4()` (POST):

ğŸ“Œ **Description:** 
Scrapes a static website and returns extracted text.

### **Request Format**
Send a **POST request** with a JSON body:
```json
{
    "url": "https://example.com"
}
```
Response Format:
```
{
    "html": "<html>...</html>"
}
```

## ğŸ“Œ How the Scraper Function Works

| Step | Description |
|------|-------------|
| **1ï¸âƒ£ Send HTTP Request** | The function **sends a request** to the specified URL using `requests.get()`. |
| **2ï¸âƒ£ Check Response Status** | If the response **is not `200 OK`**, an error is returned. |
| **3ï¸âƒ£ Parse HTML with BeautifulSoup** | The HTML content is parsed using **BeautifulSoup** to clean the page. |
| **4ï¸âƒ£ Return Cleaned HTML** | The cleaned HTML is formatted using `soup.prettify()` and returned. |


## ğŸ“Œ Error Handling

The scraper function **handles errors** and returns structured JSON responses.

| Error Type       | Status Code       | Example Response                           |
|-----------------|------------------|-------------------------------------------|
| **Missing URL**  | `400 Bad Request` | ```json {"error": "URL is required"}``` |
| **Invalid URL**  | `400 Bad Request` | ```json {"error": "Failed to retrieve content"}``` |
| **Request Timeout** | `500 Server Error` | ```json {"error": "An error occurred: timeout"}``` |

âœ… **If an error occurs, the function returns a structured JSON error message instead of crashing.**
